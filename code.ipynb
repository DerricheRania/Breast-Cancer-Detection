{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f3e3dc8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------------------\n",
    "# Breast Cancer Detection Challenge\n",
    "# --------------------------------------\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "01a1c5af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ======================\n",
    "# 1ï¸âƒ£ Dataset directories\n",
    "# ======================\n",
    "train_dir = r\"C:\\Users\\pc\\Desktop\\Pinktober2025\\Breast Cancer Detection\\train\"   \n",
    "test_dir = r\"C:\\Users\\pc\\Desktop\\Pinktober2025\\Breast Cancer Detection\\test\"     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aa3467f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 560 images belonging to 2 classes.\n",
      "Found 140 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# ======================\n",
    "# 2ï¸âƒ£ Data augmentation\n",
    "# ======================\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    shear_range=0.1,\n",
    "    zoom_range=0.1,\n",
    "    horizontal_flip=True,\n",
    "    validation_split=0.2  # split for validation\n",
    ")\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=(224, 224),\n",
    "    batch_size=16,\n",
    "    class_mode='binary',\n",
    "    subset='training'\n",
    ")\n",
    "\n",
    "val_generator = train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=(224, 224),\n",
    "    batch_size=16,\n",
    "    class_mode='binary',\n",
    "    subset='validation'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "95b32220",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ======================\n",
    "# 3ï¸âƒ£ Pretrained Model\n",
    "# ======================\n",
    "base_model = ResNet50(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "\n",
    "# Freeze the convolutional base\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Add custom classification layers\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dropout(0.3)(x)\n",
    "x = Dense(128, activation='relu')(x)\n",
    "x = Dropout(0.3)(x)\n",
    "predictions = Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "model = Model(inputs=base_model.input, outputs=predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b639d9e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ======================\n",
    "# 4ï¸âƒ£ Compile Model\n",
    "# ======================\n",
    "model.compile(optimizer=Adam(learning_rate=0.0001),\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "00a4cb4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\pc\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\trainers\\data_adapters\\py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m35/35\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 798ms/step - accuracy: 0.4716 - loss: 0.7603"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m35/35\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 1s/step - accuracy: 0.4724 - loss: 0.7603 - val_accuracy: 0.5000 - val_loss: 0.6969\n",
      "Epoch 2/20\n",
      "\u001b[1m35/35\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 929ms/step - accuracy: 0.4602 - loss: 0.7470 - val_accuracy: 0.5000 - val_loss: 0.6907\n",
      "Epoch 3/20\n",
      "\u001b[1m35/35\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 723ms/step - accuracy: 0.4829 - loss: 0.7286"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m35/35\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 926ms/step - accuracy: 0.4828 - loss: 0.7289 - val_accuracy: 0.5786 - val_loss: 0.6901\n",
      "Epoch 4/20\n",
      "\u001b[1m35/35\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 922ms/step - accuracy: 0.4502 - loss: 0.7467 - val_accuracy: 0.5000 - val_loss: 0.6915\n",
      "Epoch 5/20\n",
      "\u001b[1m35/35\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 960ms/step - accuracy: 0.5499 - loss: 0.7084 - val_accuracy: 0.5214 - val_loss: 0.6911\n",
      "Epoch 6/20\n",
      "\u001b[1m35/35\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 908ms/step - accuracy: 0.5095 - loss: 0.7227 - val_accuracy: 0.5000 - val_loss: 0.6913\n",
      "Epoch 7/20\n",
      "\u001b[1m35/35\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 890ms/step - accuracy: 0.4436 - loss: 0.7545 - val_accuracy: 0.5000 - val_loss: 0.6913\n",
      "Epoch 8/20\n",
      "\u001b[1m35/35\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 842ms/step - accuracy: 0.5124 - loss: 0.7318 - val_accuracy: 0.5000 - val_loss: 0.6920\n"
     ]
    }
   ],
   "source": [
    "# ======================\n",
    "# 5ï¸âƒ£ Training\n",
    "# ======================\n",
    "early_stop = EarlyStopping(monitor='val_accuracy', patience=5, restore_best_weights=True)\n",
    "checkpoint = ModelCheckpoint('best_model.h5', monitor='val_accuracy', save_best_only=True)\n",
    "\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    validation_data=val_generator,\n",
    "    epochs=20,\n",
    "    callbacks=[early_stop, checkpoint]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7fc97874",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 1s/step\n"
     ]
    }
   ],
   "source": [
    "# ======================\n",
    "# 6ï¸âƒ£ Predict on Test Set\n",
    "# ======================\n",
    "# List of test filenames\n",
    "from tensorflow.keras.preprocessing import image\n",
    "filenames = sorted(os.listdir(test_dir))\n",
    "\n",
    "# Prepare image arrays\n",
    "test_images = []\n",
    "for file in filenames:\n",
    "    img_path = os.path.join(test_dir, file)\n",
    "    img = image.load_img(img_path, target_size=(224, 224))\n",
    "    img_array = image.img_to_array(img) / 255.0\n",
    "    test_images.append(img_array)\n",
    "\n",
    "test_images = np.array(test_images)\n",
    "\n",
    "# Make predictions\n",
    "preds = model.predict(test_images)\n",
    "\n",
    "# Convert predictions to labels (M/N)\n",
    "pred_labels = ['M' if p > 0.5 else 'N' for p in preds]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8fe7e33d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Predictions saved to predictions.csv\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# ======================\n",
    "# 7ï¸âƒ£ Save Results\n",
    "# ======================\n",
    "results = pd.DataFrame({\n",
    "    'image file': filenames,     \n",
    "    'label': pred_labels         \n",
    "})\n",
    "\n",
    "results.to_csv('predictions_ResNet50.csv', index=False)\n",
    "print(\"âœ… Predictions saved to predictions.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe3defaf",
   "metadata": {},
   "source": [
    "### fine tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4bdab499",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================================\n",
    "# ðŸ”§ Step 1: Unfreeze the last few layers\n",
    "# =========================================\n",
    "\n",
    "# Let's unfreeze the last 20 layers of ResNet50\n",
    "for layer in base_model.layers[-20:]:\n",
    "    layer.trainable = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3815f810",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of trainable layers: 25\n"
     ]
    }
   ],
   "source": [
    "# Check how many layers are trainable now\n",
    "print(f\"Number of trainable layers: {np.sum([layer.trainable for layer in model.layers])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f7b6bf83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================================\n",
    "# ðŸ” Step 2: Recompile with smaller LR\n",
    "# =========================================\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "model.compile(\n",
    "    optimizer=Adam(learning_rate=1e-5),  # smaller LR for fine-tuning\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "04bdf1ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m35/35\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 980ms/step - accuracy: 0.5276 - loss: 0.7171"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m35/35\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 1s/step - accuracy: 0.5276 - loss: 0.7169 - val_accuracy: 0.5000 - val_loss: 0.6947\n",
      "Epoch 2/10\n",
      "\u001b[1m35/35\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 1s/step - accuracy: 0.4172 - loss: 0.7432 - val_accuracy: 0.5000 - val_loss: 0.6934\n",
      "Epoch 3/10\n",
      "\u001b[1m35/35\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 1s/step - accuracy: 0.4801 - loss: 0.7177 - val_accuracy: 0.5000 - val_loss: 0.6958\n",
      "Epoch 4/10\n",
      "\u001b[1m35/35\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 1s/step - accuracy: 0.5196 - loss: 0.6992 - val_accuracy: 0.4857 - val_loss: 0.6915\n",
      "Epoch 5/10\n",
      "\u001b[1m35/35\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 874ms/step - accuracy: 0.5018 - loss: 0.7017"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m35/35\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 1s/step - accuracy: 0.5016 - loss: 0.7019 - val_accuracy: 0.5286 - val_loss: 0.6937\n",
      "Epoch 6/10\n",
      "\u001b[1m35/35\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 1s/step - accuracy: 0.5020 - loss: 0.7089 - val_accuracy: 0.5071 - val_loss: 0.6938\n",
      "Epoch 7/10\n",
      "\u001b[1m35/35\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 1s/step - accuracy: 0.4963 - loss: 0.7152 - val_accuracy: 0.5071 - val_loss: 0.6937\n",
      "Epoch 8/10\n",
      "\u001b[1m35/35\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 1s/step - accuracy: 0.5297 - loss: 0.7100 - val_accuracy: 0.5143 - val_loss: 0.6938\n",
      "Epoch 9/10\n",
      "\u001b[1m35/35\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 1s/step - accuracy: 0.5227 - loss: 0.6932 - val_accuracy: 0.5214 - val_loss: 0.6908\n",
      "Epoch 10/10\n",
      "\u001b[1m35/35\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 855ms/step - accuracy: 0.4630 - loss: 0.7118"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m35/35\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 1s/step - accuracy: 0.4641 - loss: 0.7116 - val_accuracy: 0.5357 - val_loss: 0.6934\n"
     ]
    }
   ],
   "source": [
    "# =========================================\n",
    "# ðŸ§© Step 3: Train again with early stopping\n",
    "# =========================================\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "fine_tune_early_stop = EarlyStopping(\n",
    "    monitor='val_accuracy',\n",
    "    patience=5,\n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "fine_tune_checkpoint = ModelCheckpoint(\n",
    "    'fine_tuned_model.h5',\n",
    "    monitor='val_accuracy',\n",
    "    save_best_only=True\n",
    ")\n",
    "\n",
    "history_finetune = model.fit(\n",
    "    train_generator,\n",
    "    validation_data=val_generator,\n",
    "    epochs=10,  # fewer epochs since itâ€™s fine-tuning\n",
    "    callbacks=[fine_tune_early_stop, fine_tune_checkpoint]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cc749b1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 1s/step\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing import image\n",
    "filenames = sorted(os.listdir(test_dir))\n",
    "\n",
    "# Prepare image arrays\n",
    "test_images = []\n",
    "for file in filenames:\n",
    "    img_path = os.path.join(test_dir, file)\n",
    "    img = image.load_img(img_path, target_size=(224, 224))\n",
    "    img_array = image.img_to_array(img) / 255.0\n",
    "    test_images.append(img_array)\n",
    "\n",
    "test_images = np.array(test_images)\n",
    "\n",
    "# Make predictions\n",
    "preds = model.predict(test_images)\n",
    "pred_labels = ['M' if p > 0.5 else 'N' for p in preds]\n",
    "results.to_csv('predictions_ResNet50_FT.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b6c5112",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
